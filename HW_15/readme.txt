Легенда:
    - Клієнт для свого проєкта замовив у вас бота, який буде створювати файл з новинами про події у місті за певний день. Клієнт має певні побажання щодо формату файлу, даних у ньому та технологіях, які будуть використовуватися (клієнт планує сам підтримувати свій проєкт, але він знає лише Python та трохи розбирається у Scrapy і BeautifulSoup)
Завдання:
    Напишіть скрейпер для сайту "vikka.ua", який буде приймати від користувача дату, збирати і зберігати інформацію про новини за вказаний день.
Особливості реалізації:
    - використовувати лише Scrapy, BeautifulSoup (опціонально), lxml (опціонально) та вбудовані модулі Python
    - дані повинні зберігатися у csv файл з датою в якості назви у форматі "рік_місяць_число.csv" (напр. 2022_01_13.csv)
    - дані, які потрібно зберігати (саме в такому порядку вони мають бути у файлі):
        1. Заголовок новини
        2. Текст новини у форматі рядка без HTML тегів та у вигляді суцільного тексту (Добре: "Hello world" Погано: "<p>Hello</p><p>world</p>")
        3. Теги у форматі рядка, де всі теги записані з решіткою через кому (#назва_тегу, #назва_тегу, ...)
        4. URL новини
    - збереження даних у файл може відбуватися за бажанням або в самому спайдері, або через Pipelines (буде плюсом в карму)
    - код повинен бути написаний з дотриманням вимог PEP8 (іменування змінних, функцій, класів, порядок імпортів, відступи, коментарі, документація і т.д.)
    - клієнт не повинен здогадуватися, що у вас в голові - додайте якісь підказки там, де це необхідно
    - клієнт може випадково ввести некорректні дані, пам'ятайте про це
    - якщо клієнту доведеться відправляти вам бота на доопрацювання багато разів, або не всі його вимоги будуть виконані - він знайде іншого виконавця, а з вами договір буде розірваний. У нього в команді немає тестувальників, тому перед відправкою завдання - впевніться, що все працює і відповідає ТЗ.
    - не забудьте про requirements.txt
    - клієнт буде запускати бота через термінал командою "scrapy crawl назва_скрейпера"
Корисні посилання:
    - https://www.vikka.ua/
    - https://docs.scrapy.org/en/latest/
    - https://docs.scrapy.org/en/latest/topics/item-pipeline.html

Спайдер парсит новости на сайте vikka.com
1.Вводим дату в формате ГГГГ/ММ/ДД
2.Cобранные данные найдем по пути vikka/vikka/news